{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizar(carpeta, label):\n",
    "    archivos = os.listdir(carpeta)\n",
    "\n",
    "    # Lista para almacenar los vectores de las imágenes\n",
    "    vectores_imagenes = []\n",
    "\n",
    "    # Iterar sobre los archivos\n",
    "    for archivo in archivos:\n",
    "        # Comprobar si es un archivo de imagen\n",
    "        if archivo.endswith(\".jpg\") or archivo.endswith(\".png\"):\n",
    "            # Ruta completa de la imagen\n",
    "            ruta_imagen = os.path.join(carpeta, archivo)\n",
    "            \n",
    "            # Cargar la imagen\n",
    "            imagen = Image.open(ruta_imagen)\n",
    "\n",
    "            # Redimensiona la imagen a 8x8 píxeles\n",
    "            imagen = imagen.resize((50, 125))\n",
    "\n",
    "            # Convierte la imagen a escala de grises\n",
    "            imagen = imagen.convert(\"L\")\n",
    "\n",
    "            # Convierte la imagen a un array de NumPy\n",
    "            array_imagen = np.array(imagen)\n",
    "\n",
    "            # Aplana el array de imagen a un vector de 1x64\n",
    "            vector = array_imagen.flatten()\n",
    "            \n",
    "            # Crea una lista con la etiqueta y el nombre del archivo\n",
    "            etiqueta_archivo = [label, archivo]\n",
    "\n",
    "            # Agrega la lista al final del vector\n",
    "            vector_con_etiqueta_archivo = np.append(vector, etiqueta_archivo)\n",
    "\n",
    "            # Agrega el vector a la lista de vectores de imágenes\n",
    "            vectores_imagenes.append(vector_con_etiqueta_archivo)\n",
    "\n",
    "    # Convierte la lista de vectores en una matriz de NumPy\n",
    "    return np.array(vectores_imagenes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yes = vectorizar('carpeta_MitadesYes/', 1)\n",
    "data_no = vectorizar('carpeta_MitadesNo/', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_pred = []\n",
    "        for i in range(len(X_test)):\n",
    "            distances = []\n",
    "            for j in range(len(self.X_train)):\n",
    "                dist = euclidean_distance(X_test[i], self.X_train[j])\n",
    "                distances.append((dist, self.y_train[j]))\n",
    "            distances.sort(key=lambda x: x[0])  # Ordenar distancias de menor a mayor\n",
    "            neighbors = distances[:self.k]  # Obtener los k vecinos más cercanos\n",
    "            classes = [neighbor[1] for neighbor in neighbors]  # Obtener las clases de los vecinos\n",
    "            y_pred.append(max(set(classes), key=classes.count))  # Clasificación por voto mayoritario\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude(matriz, indice):\n",
    "    filas_seleccionadas = []\n",
    "    for i, fila in enumerate(matriz):\n",
    "        if i != indice:\n",
    "            filas_seleccionadas.append(fila)\n",
    "    return np.array(filas_seleccionadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeData(data1, data2):\n",
    "    return np.concatenate((data1, data2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOO_Knn(data_yes, data_no):\n",
    "    allData = mergeData(data_yes, data_no)\n",
    "    \n",
    "    predicted_labels = []\n",
    "    true_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 6252)\n"
     ]
    }
   ],
   "source": [
    "allData = mergeData(data_yes, data_no)\n",
    "print(allData.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOO_Knn(allData):\n",
    "    labelsPredictedKNN = []\n",
    "    labelReal = allData[:, 6250]\n",
    "    for i in range(allData.shape[0]):\n",
    "        dataTrain = exclude(allData, i)\n",
    "        ImgsTrain = np.array(dataTrain[:, :-2], dtype= int)\n",
    "        LabelsTrain = np.array(dataTrain[:, 6250], dtype= int)\n",
    "        NameImageTrain = np.array(dataTrain[:, 6251], dtype= str)  \n",
    "\n",
    "\n",
    "        dataTest = allData[i, :]\n",
    "        dataTest = dataTest.reshape(1, 6252)\n",
    "        ImgsTest = np.array(dataTest[:, :-2], dtype=int)\n",
    "        LabelsTest = np.array(dataTest[:, 6250], dtype=int)\n",
    "        NameImageTest = np.array(dataTest[:, 6251], dtype=str)\n",
    "\n",
    "        knn = KNNClassifier(1)\n",
    "        knn.fit(ImgsTrain, LabelsTrain)\n",
    "        prediction = knn.predict(ImgsTest)\n",
    "        \n",
    "        labelsPredictedKNN.append(prediction[0])\n",
    "        print(prediction[0], LabelsTest[0])\n",
    "    labelsPredictedKNN = np.array(labelsPredictedKNN)  \n",
    "    return(labelsPredictedKNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def __init__(self, k, max_iterations):\n",
    "        self.k = k\n",
    "        self.max_iterations = max_iterations\n",
    "        self.centroids = None\n",
    "        self.labels = None\n",
    "\n",
    "    def initialize_centroids(self, data):\n",
    "        # Inicialización de centroides de manera aleatoria\n",
    "        np.random.seed(0)\n",
    "        indices = np.random.choice(data.shape[0], self.k, replace=False)\n",
    "        centroids = data[indices]\n",
    "        return centroids\n",
    "    \n",
    "    def initialize_centroids_with_features(self, data, real_labels):\n",
    "        # Preprocesamiento de las imágenes\n",
    "        flattened_images = data.reshape(data.shape[0], -1)  # Aplanar las imágenes en vectores de características\n",
    "        unique_labels = np.unique(real_labels)\n",
    "\n",
    "        # Cálculo de características promedio por etiqueta\n",
    "        centroids = []\n",
    "        for label in unique_labels:\n",
    "            label_images = flattened_images[real_labels == label]\n",
    "            label_mean = np.mean(label_images, axis=0)\n",
    "            centroids.append(label_mean)\n",
    "\n",
    "        # Selección de los primeros K centroides iniciales\n",
    "        centroids = np.array(centroids)[:self.k]\n",
    "\n",
    "        return centroids\n",
    "    \n",
    "    def kmeans_plusplus_initialization(self, data, k):\n",
    "        centroids = []\n",
    "        centroids.append(data[np.random.choice(data.shape[0])])  # Selecciona el primer centroide aleatoriamente\n",
    "\n",
    "        for _ in range(1, k):\n",
    "            distances = np.array([min([np.linalg.norm(point - centroid) for centroid in centroids]) for point in data])\n",
    "            probabilities = distances / distances.sum()\n",
    "            next_centroid_index = np.random.choice(data.shape[0], p=probabilities)\n",
    "            centroids.append(data[next_centroid_index])\n",
    "\n",
    "        return np.array(centroids)\n",
    "\n",
    "    def assign_clusters(self, data):\n",
    "        # Asignación de puntos a clústeres según la distancia euclidiana\n",
    "        distances = np.sqrt(((data[:, np.newaxis] - self.centroids) ** 2).sum(axis=2))\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "        return labels\n",
    "\n",
    "    def update_centroids(self, data):\n",
    "        # Actualización de los centroides como la media de los puntos asignados a cada clúster\n",
    "        centroids = np.zeros((self.k, data.shape[1]))\n",
    "        for i in range(self.k):\n",
    "            cluster_data = data[self.labels == i]\n",
    "            if len(cluster_data) > 0:\n",
    "                centroids[i] = np.mean(cluster_data, axis=0)\n",
    "        return centroids\n",
    "\n",
    "    def fitRANDOM(self, data):\n",
    "        self.centroids = self.initialize_centroids(data)\n",
    "\n",
    "        for _ in range(self.max_iterations):\n",
    "            prev_centroids = self.centroids.copy()\n",
    "\n",
    "            self.labels = self.assign_clusters(data)\n",
    "            self.centroids = self.update_centroids(data)\n",
    "\n",
    "            # Comprobar convergencia\n",
    "            if np.all(prev_centroids == self.centroids):\n",
    "                break\n",
    "            \n",
    "    def fitPreprocess(self, data, real_labels):\n",
    "        self.centroids = self.initialize_centroids_with_features(data, real_labels)\n",
    "\n",
    "        for _ in range(self.max_iterations):\n",
    "            prev_centroids = self.centroids.copy()\n",
    "\n",
    "            self.labels = self.assign_clusters(data)\n",
    "            self.centroids = self.update_centroids(data)\n",
    "\n",
    "            # Comprobar convergencia\n",
    "            if np.all(prev_centroids == self.centroids):\n",
    "                break\n",
    "    \n",
    "    def fitKplus(self, data):\n",
    "        self.centroids = self.initialize_centroids_with_features(data, self.k)\n",
    "\n",
    "        for _ in range(self.max_iterations):\n",
    "            prev_centroids = self.centroids.copy()\n",
    "\n",
    "            self.labels = self.assign_clusters(data)\n",
    "            self.centroids = self.update_centroids(data)\n",
    "\n",
    "            # Comprobar convergencia\n",
    "            if np.array_equal(prev_centroids, self.centroids):\n",
    "                break\n",
    "\n",
    "    def predict(self, data):\n",
    "        labels = self.assign_clusters(data)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOO_KMeans(allData):\n",
    "    labelsPre = []\n",
    "    labelsR = []\n",
    "    labelsPlus = []\n",
    "    for i in range(allData.shape[0]):\n",
    "        dataTrain = exclude(allData, i)\n",
    "        ImgsTrain = np.array(dataTrain[:, :-2], dtype= int)\n",
    "        LabelsTrain = np.array(dataTrain[:, 6250], dtype= int)\n",
    "        NameImageTrain = np.array(dataTrain[:, 6251], dtype= str)  \n",
    "\n",
    "\n",
    "        dataTest = allData[i, :]\n",
    "        dataTest = dataTest.reshape(1, 6252)\n",
    "        ImgsTest = np.array(dataTest[:, :-2], dtype=int)\n",
    "        LabelsTest = np.array(dataTest[:, 6250], dtype=int)\n",
    "        NameImageTest = np.array(dataTest[:, 6251], dtype=str)\n",
    "\n",
    "        iterations, k=2, 2\n",
    "\n",
    "        kmeansPre = KMeans(k,iterations)\n",
    "        kmeansR = KMeans(k,iterations)\n",
    "        kmeansPlus = KMeans(k,iterations)\n",
    "        # Ajustar el modelo a los datos\n",
    "        kmeansPre.fitPreprocess(ImgsTrain, LabelsTrain)\n",
    "        kmeansR.fitRANDOM(ImgsTrain)\n",
    "        kmeansPlus.fitKplus(ImgsTrain)\n",
    "        # Obtener las etiquetas asignadas a cada punto\n",
    "        predicted_labelsPre = kmeansPre.predict(ImgsTest)\n",
    "        predicted_labelsR = kmeansR.predict(ImgsTest)\n",
    "        predicted_labelsPlus = kmeansPlus.predict(ImgsTest)\n",
    "        \n",
    "        labelsPre.append(predicted_labelsPre[0])\n",
    "        labelsR.append(predicted_labelsR[0])\n",
    "        labelsPlus.append(predicted_labelsPlus[0])\n",
    "    \n",
    "    accuracyPre = np.mean(labelsPre == np.array(allData[:, 6250], dtype=int))\n",
    "    accuracyR = np.mean(labelsR == np.array(allData[:, 6250], dtype=int))\n",
    "    accuracyPlus = np.mean(labelsPlus == np.array(allData[:, 6250], dtype=int))\n",
    "    \n",
    "    print(accuracyPre,accuracyR,accuracyPlus)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6859903381642513 0.5555555555555556 0.4782608695652174\n"
     ]
    }
   ],
   "source": [
    "LOO_KMeans(allData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "0 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "1 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "predictions = LOO_Knn(allData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(np.array(allData[:, 6250], dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8164251207729468\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(predictions == np.array(allData[:, 6250], dtype=int))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' '1' '0' '1' '1' '1' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0'\n",
      " '1' '0' '0' '1' '0' '1' '1' '1' '1' '1' '0' '1' '1' '1' '0' '0' '1' '0'\n",
      " '0' '0' '1' '1' '1' '1' '1' '1' '1' '1' '0' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '0' '0' '0' '0' '0' '1' '0' '1' '1' '1' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '1' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' 'mitad_N51.jpg'\n",
      " 'mitad_N59.jpg' 'mitad_Y10.jpg' 'mitad_Y102.jpg' 'mitad_Y106.jpg'\n",
      " 'mitad_Y108.jpg' 'mitad_Y110.jpg' 'mitad_Y119.jpg' 'mitad_Y121.jpg'\n",
      " 'mitad_Y123.jpg' 'mitad_Y125.jpg' 'mitad_Y127.jpg' 'mitad_Y129.jpg'\n",
      " 'mitad_Y130.jpg' 'mitad_Y132.jpg' 'mitad_Y134.jpg' 'mitad_Y136.jpg'\n",
      " 'mitad_Y138.jpg' 'mitad_Y14.jpg' 'mitad_Y141.jpg' 'mitad_Y143.jpg'\n",
      " 'mitad_Y145.jpg' 'mitad_Y149.jpg' 'mitad_Y16.jpg' 'mitad_Y2.jpg'\n",
      " 'mitad_Y21.jpg' 'mitad_Y24.jpg' 'mitad_Y26.jpg' 'mitad_Y28.jpg'\n",
      " 'mitad_Y3.jpg' 'mitad_Y31.jpg' 'mitad_Y33.jpg' 'mitad_Y35.jpg'\n",
      " 'mitad_Y38.jpg' 'mitad_Y4.jpg' 'mitad_Y42.jpg' 'mitad_Y46.jpg'\n",
      " 'mitad_Y5.jpg' 'mitad_Y52.jpg' 'mitad_Y54.jpg' 'mitad_Y56.jpg'\n",
      " 'mitad_Y59.jpg' 'mitad_Y60.jpg' 'mitad_Y62.jpg' 'mitad_Y64.jpg'\n",
      " 'mitad_Y69.jpg' 'mitad_Y70.jpg' 'mitad_Y73.jpg' 'mitad_Y76.jpg'\n",
      " 'mitad_Y78.jpg' 'mitad_Y8.jpg' 'mitad_Y81.jpg' 'mitad_Y83.jpg'\n",
      " 'mitad_Y87.jpg' 'mitad_Y9.jpg' 'mitad_Y91.jpg' 'mitad_Y93.jpg'\n",
      " 'mitad_Y95.jpg' 'mitad_N1.jpg' 'mitad_N11.jpg' 'mitad_N13.jpg'\n",
      " 'mitad_N15.jpg' 'mitad_N17.jpg' 'mitad_N19.jpg' 'mitad_N20.jpg'\n",
      " 'mitad_N22.jpg' 'mitad_N24.jpg' 'mitad_N26.jpg' 'mitad_N28.jpg'\n",
      " 'mitad_N3.jpg' 'mitad_N31.jpg' 'mitad_N33.jpg' 'mitad_N35.jpg'\n",
      " 'mitad_N38.jpg' 'mitad_N4.jpg' 'mitad_N41.jpg' 'mitad_N43.jpg'\n",
      " 'mitad_N45.jpg' 'mitad_N47.jpg' 'mitad_N49.jpg' 'mitad_N52.jpg'\n",
      " 'mitad_N54.jpg' 'mitad_N57.jpg' 'mitad_N6.jpg' 'mitad_N62.jpg'\n",
      " 'mitad_N64.jpg' 'mitad_N66.jpg' 'mitad_N68.jpg' 'mitad_N7.jpg'\n",
      " 'mitad_N71.jpg' 'mitad_N73.jpg' 'mitad_N75.jpg' 'mitad_N77.jpg'\n",
      " 'mitad_N79.jpg' 'mitad_N80.jpg' 'mitad_N82.jpg' 'mitad_N84.jpg'\n",
      " 'mitad_N86.jpg' 'mitad_N88.jpg' 'mitad_N9.jpg' 'mitad_N91.jpg'\n",
      " 'mitad_N94.jpg' 'mitad_N96.jpg' 'mitad_N98.jpg']\n"
     ]
    }
   ],
   "source": [
    "NamePredicction =  mergeData(predictions,allData[:, 6251])\n",
    "NamePredicction = NamePredicction.reshape(2, 207)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
