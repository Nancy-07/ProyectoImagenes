{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "from PIL import Image\n",
    "from scipy.stats import pearsonr\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sacarDiferencia(carpeta, newCarpeta):\n",
    "    # Crear la carpeta de imágenes de diferencia si no existe\n",
    "    if not os.path.exists(newCarpeta):\n",
    "        os.makedirs(newCarpeta)\n",
    "\n",
    "    # Obtener la lista de archivos en la carpeta\n",
    "    archivos = os.listdir(carpeta)\n",
    "\n",
    "    # Iterar sobre los archivos\n",
    "    for archivo in archivos:\n",
    "        # Comprobar si es un archivo de imagen\n",
    "        if archivo.endswith(\".jpg\") or archivo.endswith(\".png\"):\n",
    "            # Ruta completa de la imagen\n",
    "            ruta_imagen = os.path.join(carpeta, archivo)\n",
    "\n",
    "            # Cargar la imagen\n",
    "            imagen = cv2.imread(ruta_imagen, 0)\n",
    "            imagen = cv2.normalize(imagen, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "            # Eliminación de ruido con filtrado de media\n",
    "            imagen = cv2.medianBlur(imagen, 5)\n",
    "\n",
    "            # Mejora de la nitidez utilizando filtrado bilateral\n",
    "            imagen = cv2.bilateralFilter(imagen, 9, 75, 75)\n",
    "\n",
    "            # Obtener dimensiones de la imagen\n",
    "            alto, ancho = imagen.shape\n",
    "\n",
    "            # Dividir la imagen en mitades\n",
    "            mitad_izquierda = imagen[:, :ancho // 2]\n",
    "            mitad_derecha = imagen[:, ancho // 2:]\n",
    "\n",
    "            # Aplicar efecto espejo vertical a la mitad derecha\n",
    "            mitad_derecha_espejo = cv2.flip(mitad_derecha, 1)\n",
    "\n",
    "            # Calcular la diferencia entre las mitades izquierda y derecha\n",
    "            # diferencia = cv2.subtract(mitad_izquierda, mitad_derecha_espejo)\n",
    "            diferencia = np.abs(mitad_izquierda.astype(int) - mitad_derecha_espejo.astype(int))\n",
    "\n",
    "            # Convertir la imagen de diferencia a CV_8U\n",
    "            diferencia = cv2.convertScaleAbs(diferencia)\n",
    "\n",
    "            d = 3\n",
    "            sigmaColor = 200\n",
    "            sigmaSpace = 1000\n",
    "\n",
    "            # Aplicar el filtro bilateral\n",
    "            diferencia = cv2.bilateralFilter(diferencia, d, sigmaColor, sigmaSpace)\n",
    "\n",
    "            # Guardar la imagen de diferencia en escala de grises\n",
    "            nombre_grafica = \"mitad_\" + archivo\n",
    "            ruta_grafica = os.path.join(newCarpeta, nombre_grafica)\n",
    "            cv2.imwrite(ruta_grafica, diferencia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def vectorizar(carpeta, label):\n",
    "    archivos = os.listdir(carpeta)\n",
    "\n",
    "    # Lista para almacenar los vectores de las imágenes\n",
    "    vectores_imagenes = []\n",
    "\n",
    "    # Iterar sobre los archivos\n",
    "    for archivo in archivos:\n",
    "        # Comprobar si es un archivo de imagen\n",
    "        if archivo.endswith(\".jpg\") or archivo.endswith(\".png\"):\n",
    "            # Ruta completa de la imagen\n",
    "            ruta_imagen = os.path.join(carpeta, archivo)\n",
    "            \n",
    "            # Cargar la imagen\n",
    "            imagen = Image.open(ruta_imagen)\n",
    "\n",
    "            # Redimensiona la imagen a 8x8 píxeles\n",
    "            imagen = imagen.resize((50, 125))\n",
    "\n",
    "            # Convierte la imagen a escala de grises\n",
    "            imagen = imagen.convert(\"L\")\n",
    "\n",
    "            # Convierte la imagen a un array de NumPy\n",
    "            array_imagen = np.array(imagen)\n",
    "\n",
    "            # Aplana el array de imagen a un vector de 1x64\n",
    "            vector = array_imagen.flatten()\n",
    "            \n",
    "            # Crea una lista con la etiqueta y el nombre del archivo\n",
    "            etiqueta_archivo = [label, archivo]\n",
    "\n",
    "            # Agrega la lista al final del vector\n",
    "            vector_con_etiqueta_archivo = np.append(vector, etiqueta_archivo)\n",
    "\n",
    "            # Agrega el vector a la lista de vectores de imágenes\n",
    "            vectores_imagenes.append(vector_con_etiqueta_archivo)\n",
    "\n",
    "    # Convierte la lista de vectores en una matriz de NumPy\n",
    "    return np.array(vectores_imagenes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sacarDiferencia('yes_nuevo/','./carpeta_MitadesYes/')\n",
    "data_yes = vectorizar('carpeta_MitadesYes/', 1)\n",
    "\n",
    "sacarDiferencia('no_nuevo/','./carpeta_MitadesNo/')\n",
    "data_no = vectorizar('carpeta_MitadesNo/', 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divideTrainTest(data, porcentainTrain):\n",
    "    # Número de filas a seleccionar\n",
    "    num_filas_seleccionadas = int(porcentainTrain * data.shape[0])\n",
    "\n",
    "    # Generar índices aleatorios de las filas a seleccionar\n",
    "    indices_seleccionados = np.random.choice(data.shape[0], num_filas_seleccionadas, replace=False)\n",
    "\n",
    "    # Crear la matriz con las filas seleccionadas\n",
    "    Train = data[indices_seleccionados, :]\n",
    "\n",
    "    # Crear la matriz con las filas no seleccionadas\n",
    "    indices_no_seleccionados = np.setdiff1d(np.arange(data.shape[0]), indices_seleccionados)\n",
    "    Test = data[indices_no_seleccionados, :]\n",
    "    \n",
    "    return Train, Test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeData(data1, data2):\n",
    "    return np.concatenate((data1, data2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_pred = []\n",
    "        for i in range(len(X_test)):\n",
    "            distances = []\n",
    "            for j in range(len(self.X_train)):\n",
    "                dist = euclidean_distance(X_test[i], self.X_train[j])\n",
    "                distances.append((dist, self.y_train[j]))\n",
    "            distances.sort(key=lambda x: x[0])  # Ordenar distancias de menor a mayor\n",
    "            neighbors = distances[:self.k]  # Obtener los k vecinos más cercanos\n",
    "            classes = [neighbor[1] for neighbor in neighbors]  # Obtener las clases de los vecinos\n",
    "            y_pred.append(max(set(classes), key=classes.count))  # Clasificación por voto mayoritario\n",
    "        return y_pred\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnAlgorithm(X_train, Y_train, X_test, Y_test, k):\n",
    "    clases = np.unique(Y_train)\n",
    "    confussionMatrix = np.zeros((len(clases),len(clases)), dtype=int)\n",
    "    knn = KNNClassifier(k)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    predictions = knn.predict(X_test)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def __init__(self, k, max_iterations):\n",
    "        self.k = k\n",
    "        self.max_iterations = max_iterations\n",
    "        self.centroids = None\n",
    "        self.labels = None\n",
    "\n",
    "    def initialize_centroids(self, data):\n",
    "        # Inicialización de centroides de manera aleatoria\n",
    "        np.random.seed(0)\n",
    "        indices = np.random.choice(data.shape[0], self.k, replace=False)\n",
    "        centroids = data[indices]\n",
    "        return centroids\n",
    "    \n",
    "    def initialize_centroids_with_features(self, data, real_labels):\n",
    "        # Preprocesamiento de las imágenes\n",
    "        flattened_images = data.reshape(data.shape[0], -1)  # Aplanar las imágenes en vectores de características\n",
    "        unique_labels = np.unique(real_labels)\n",
    "\n",
    "        # Cálculo de características promedio por etiqueta\n",
    "        centroids = []\n",
    "        for label in unique_labels:\n",
    "            label_images = flattened_images[real_labels == label]\n",
    "            label_mean = np.mean(label_images, axis=0)\n",
    "            centroids.append(label_mean)\n",
    "\n",
    "        # Selección de los primeros K centroides iniciales\n",
    "        centroids = np.array(centroids)[:self.k]\n",
    "\n",
    "        return centroids\n",
    "    \n",
    "    def kmeans_plusplus_initialization(self, data, k):\n",
    "        centroids = []\n",
    "        centroids.append(data[np.random.choice(data.shape[0])])  # Selecciona el primer centroide aleatoriamente\n",
    "\n",
    "        for _ in range(1, k):\n",
    "            distances = np.array([min([np.linalg.norm(point - centroid) for centroid in centroids]) for point in data])\n",
    "            probabilities = distances / distances.sum()\n",
    "            next_centroid_index = np.random.choice(data.shape[0], p=probabilities)\n",
    "            centroids.append(data[next_centroid_index])\n",
    "\n",
    "        return np.array(centroids)\n",
    "\n",
    "    def assign_clusters(self, data):\n",
    "        # Asignación de puntos a clústeres según la distancia euclidiana\n",
    "        distances = np.sqrt(((data[:, np.newaxis] - self.centroids) ** 2).sum(axis=2))\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "        return labels\n",
    "\n",
    "    def update_centroids(self, data):\n",
    "        # Actualización de los centroides como la media de los puntos asignados a cada clúster\n",
    "        centroids = np.zeros((self.k, data.shape[1]))\n",
    "        for i in range(self.k):\n",
    "            cluster_data = data[self.labels == i]\n",
    "            if len(cluster_data) > 0:\n",
    "                centroids[i] = np.mean(cluster_data, axis=0)\n",
    "        return centroids\n",
    "\n",
    "    def fitRANDOM(self, data):\n",
    "        self.centroids = self.initialize_centroids(data)\n",
    "\n",
    "        for _ in range(self.max_iterations):\n",
    "            prev_centroids = self.centroids.copy()\n",
    "\n",
    "            self.labels = self.assign_clusters(data)\n",
    "            self.centroids = self.update_centroids(data)\n",
    "\n",
    "            # Comprobar convergencia\n",
    "            if np.all(prev_centroids == self.centroids):\n",
    "                break\n",
    "            \n",
    "    def fitPreprocess(self, data, real_labels):\n",
    "        self.centroids = self.initialize_centroids_with_features(data, real_labels)\n",
    "\n",
    "        for _ in range(self.max_iterations):\n",
    "            prev_centroids = self.centroids.copy()\n",
    "\n",
    "            self.labels = self.assign_clusters(data)\n",
    "            self.centroids = self.update_centroids(data)\n",
    "\n",
    "            # Comprobar convergencia\n",
    "            if np.all(prev_centroids == self.centroids):\n",
    "                break\n",
    "    \n",
    "    def fitKplus(self, data):\n",
    "        self.centroids = self.initialize_centroids_with_features(data, self.k)\n",
    "\n",
    "        for _ in range(self.max_iterations):\n",
    "            prev_centroids = self.centroids.copy()\n",
    "\n",
    "            self.labels = self.assign_clusters(data)\n",
    "            self.centroids = self.update_centroids(data)\n",
    "\n",
    "            # Comprobar convergencia\n",
    "            if np.array_equal(prev_centroids, self.centroids):\n",
    "                break\n",
    "\n",
    "    def predict(self, data):\n",
    "        labels = self.assign_clusters(data)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confusion_matrix(true_labels, predicted_labels, num_classes):\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes))\n",
    "    for true_label, predicted_label in zip(true_labels, predicted_labels):\n",
    "        confusion_matrix[true_label][predicted_label] += 1\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareKmeansAndKnn(X_train ,Y_train, X_test, Y_test, iterations, k = 2 ):\n",
    "    kmeansPre = KMeans(k,iterations)\n",
    "    kmeansR = KMeans(k,iterations)\n",
    "    kmeansPlus = KMeans(k,iterations)\n",
    "    # Ajustar el modelo a los datos\n",
    "    kmeansPre.fitPreprocess(X_train, Y_train)\n",
    "    kmeansR.fitRANDOM(X_train)\n",
    "    kmeansPlus.fitKplus(X_train)\n",
    "    # Obtener las etiquetas asignadas a cada punto\n",
    "    predicted_labelsPre = kmeansPre.predict(X_test)\n",
    "    predicted_labelsR = kmeansR.predict(X_test)\n",
    "    predicted_labelsPlus = kmeansPlus.predict(X_test)\n",
    "    # Calcular la matriz de confusión\n",
    "    accuracyPre = np.mean(predicted_labelsPre == Y_test)\n",
    "    accuracyR = np.mean(predicted_labelsPre == Y_test)\n",
    "    accuracyPlus = np.mean(predicted_labelsPre == Y_test)\n",
    "    \n",
    "    '''confusion_matrixPre = calculate_confusion_matrix(Y_test, predicted_labelsPre, num_classes=k)\n",
    "    confusion_matrixR = calculate_confusion_matrix(Y_test, predicted_labelsR, num_classes=k)\n",
    "    confusion_matrixPlus = calculate_confusion_matrix(Y_test, predicted_labelsPlus, num_classes=k)\n",
    "    \n",
    "    # Imprimir la matriz de confusión\n",
    "    print(\"Matriz de Confusión:\")\n",
    "    print(confusion_matrix)\n",
    "\n",
    "    # Calcular la precisión como la suma de las coincidencias diagonales dividida por el número total de puntos\n",
    "    accuracyPre = np.sum(np.max(confusion_matrixPre, axis=1)) / len(X_test)\n",
    "    accuracyR = np.sum(np.max(confusion_matrixR, axis=1)) / len(X_test)\n",
    "    accuracyPlus = np.sum(np.max(confusion_matrixPlus, axis=1)) / len(X_test)'''\n",
    "    # Imprimir la precisión\n",
    "    print(\"Precisión de clasificación con preprocesamiento: {:.2f}%\".format(accuracyPre * 100))\n",
    "    print(\"Precisión de clasificación con Random: {:.2f}%\".format(accuracyR * 100))\n",
    "    print(\"Precisión de clasificación con K++: {:.2f}% \\n\".format(accuracyPlus * 100))\n",
    "    \n",
    "    KNN = knnAlgorithm(X_train, Y_train, X_test, Y_test, 1)\n",
    "    accuracyKNN = KNN[0]\n",
    "    predicted_labelsKNN = KNN [1]\n",
    "    # Crear una lista de tuplas con los valores de precisión y las etiquetas correspondientes\n",
    "    resultados = [(accuracyPre, predicted_labelsPre ), (accuracyR, predicted_labelsR), (accuracyPlus, predicted_labelsPlus), (accuracyKNN, np.array(predicted_labelsKNN))]\n",
    "\n",
    "    # Encontrar el resultado con la precisión más alta\n",
    "    mejor_resultado = max(resultados, key=lambda x: x[0])\n",
    "\n",
    "    # Devolver las etiquetas del mejor resultado\n",
    "    return mejor_resultado[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(data_yes.shape)\\nprint(data_trainY.shape)\\nprint(data_testY.shape)'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dividedY = divideTrainTest(data_yes, 0.7)\n",
    "\n",
    "data_trainY = data_dividedY[0]\n",
    "data_testY = data_dividedY[1]\n",
    "\n",
    "\n",
    "data_dividedN = divideTrainTest(data_no, 0.7)\n",
    "data_trainN = data_dividedN[0]\n",
    "data_testN = data_dividedN[1]\n",
    "'''\n",
    "print(data_yes.shape)\n",
    "print(data_trainY.shape)\n",
    "print(data_testY.shape)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude(matriz, indice):\n",
    "    filas_seleccionadas = []\n",
    "    for i, fila in enumerate(matriz):\n",
    "        if i != indice:\n",
    "            filas_seleccionadas.append(fila)\n",
    "    return np.array(filas_seleccionadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 6252)\n",
      "(63, 6252)\n"
     ]
    }
   ],
   "source": [
    "dataTrain = mergeData(data_trainY, data_trainN)\n",
    "print(dataTrain.shape) \n",
    "#print(dataTrain)\n",
    "dataTest = mergeData(data_testY, data_testN)\n",
    "print(dataTest.shape)\n",
    "#print(dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImgsTrain = np.array(dataTrain[:, :-2], dtype= int)\n",
    "LabelsTrain = np.array(dataTrain[:, 6250], dtype= int)\n",
    "NameImageTrain = np.array(dataTrain[:, 6251], dtype= str)\n",
    "\n",
    "ImgsTest = np.array(dataTest[:, :-2], dtype= int)\n",
    "LabelsTest = np.array(dataTest[:, 6250], dtype= int)\n",
    "NameImageTest = np.array(dataTest[:, 6251], dtype= str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBetterVersion(data_yes, data_no, porcentage):\n",
    "    data_dividedY = divideTrainTest(data_yes, porcentage)\n",
    "    data_trainY = data_dividedY[0]\n",
    "    data_testY = data_dividedY[1]\n",
    "    \n",
    "    data_dividedN = divideTrainTest(data_no, porcentage)\n",
    "    data_trainN = data_dividedN[0]\n",
    "    data_testN = data_dividedN[1]\n",
    "    \n",
    "    \n",
    "    dataTrain = mergeData(data_trainY, data_trainN)\n",
    "    dataTest = mergeData(data_testY, data_testN)\n",
    "    \n",
    "    ImgsTrain = np.array(dataTrain[:, :-2], dtype= int)\n",
    "    LabelsTrain = np.array(dataTrain[:, 6250], dtype= int)\n",
    "    NameImageTrain = np.array(dataTrain[:, 6251], dtype= str)\n",
    "\n",
    "    ImgsTest = np.array(dataTest[:, :-2], dtype= int)\n",
    "    LabelsTest = np.array(dataTest[:, 6250], dtype= int)\n",
    "    NameImageTest = np.array(dataTest[:, 6251], dtype= str)\n",
    "    \n",
    "    KNN = knnAlgorithm(ImgsTrain, LabelsTrain, ImgsTest, LabelsTest, 1)\n",
    "    accuracyKNN = KNN[0]\n",
    "    predicted_labelsKNN = np.array(KNN [1])\n",
    "    print(predicted_labelsKNN.shape)\n",
    "    newArchives = mergeData(NameImageTest, predicted_labelsKNN)\n",
    "    newArchives = mergeData(newArchives, LabelsTest)\n",
    "    newArchives = newArchives.reshape(3, newArchives.shape[0]//3) \n",
    "    print(newArchives.shape)\n",
    "    return (newArchives)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy with k =  1  is  100.0 % \n",
      "(2,)\n",
      "(3, 2)\n",
      "           Imagen Etiqueta Etiqueta real\n",
      "0  mitad_Y128.jpg        1             1\n",
      "1   mitad_N53.jpg        0             0\n"
     ]
    }
   ],
   "source": [
    "archives = getBetterVersion(data_yes, data_no, 0.999)\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Imagen': archives[0], 'Etiqueta': archives[1], 'Etiqueta real': archives[2]})\n",
    "# Mostrar el DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nivel de certeza: 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "certeza = (df['Etiqueta'] == df['Etiqueta real']).sum() / len(df)\n",
    "\n",
    "print(f\"Nivel de certeza: {certeza}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def LOO_Knn(data_yes, data_no):\n",
    "    allData = mergeData(data_yes, data_no)\n",
    "    \n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "\n",
    "    for i in range(allData.shape[0]):\n",
    "        dataTrain = np.delete(allData, i, axis=0)  # Eliminar la fila correspondiente al índice i\n",
    "        \n",
    "        ImgsTrain = np.array(dataTrain[:, :-2], dtype=int)\n",
    "        LabelsTrain = np.array(dataTrain[:, 6250], dtype=int)\n",
    "        NameImageTrain = np.array(dataTrain[:, 6251], dtype=str)\n",
    "        \n",
    "        ImgsTest = np.array(allData[i, :-2], dtype=int)\n",
    "        LabelsTest = np.array(allData[i, 6250], dtype=int)\n",
    "        NameImageTest = np.array(allData[i, 6251], dtype=str)\n",
    "\n",
    "        predicted_labelsKNN = np.array(knnAlgorithm(ImgsTrain, LabelsTrain, ImgsTest, LabelsTest, 1))\n",
    "        print(predicted_labelsKNN.shape)\n",
    "        print(i, predicted_labelsKNN, LabelsTest)\n",
    "        predicted_labels.append(predicted_labelsKNN[0])  # Agregar solo el primer valor de la lista\n",
    "        true_labels.append(LabelsTest)\n",
    "        \n",
    "    # Calcular la precisión general\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    print(\"Precisión del clasificador KNN con Leave-One-Out: {:.2f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6250,)\n",
      "0 [0 0 0 ... 0 0 0] 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30236\\1224099609.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLOO_Knn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_yes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30236\\1535399512.py\u001b[0m in \u001b[0;36mLOO_Knn\u001b[1;34m(data_yes, data_no)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mNameImageTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6251\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mpredicted_labelsKNN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknnAlgorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImgsTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLabelsTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImgsTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLabelsTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_labelsKNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_labelsKNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLabelsTest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30236\\3559601650.py\u001b[0m in \u001b[0;36mknnAlgorithm\u001b[1;34m(X_train, Y_train, X_test, Y_test, k)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mknn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNNClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30236\\1002379473.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X_test)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                 \u001b[0mdistances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mdistances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Ordenar distancias de menor a mayor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30236\\1002379473.py\u001b[0m in \u001b[0;36meuclidean_distance\u001b[1;34m(x1, x2)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mKNNClassifier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\settings\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\settings\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2296\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2298\u001b[1;33m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[0;32m   2299\u001b[0m                           initial=initial, where=where)\n\u001b[0;32m   2300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\settings\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LOO_Knn(data_yes, data_no)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
